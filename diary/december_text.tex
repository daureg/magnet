\section{Problem}

In \pcc{}, we have a set of $n$ objects and a binary relationship between them
denoting similarity $(+)$  or dissimilarity $(-)$. Such data are naturally
associated with a signed graph. The objective is to cluster them according to
this similarity information.
Given any node partition, a \emph{disagreements edge} is a positive edge within a
cluster or a negative edge between different clusters. A natural complexity
measure for the edge labeling (the signs associated with edges) is the minimum
number of disagreement edges over \textbf{all} possible node partitions of the node
set.

The problem of finding a partition minimizing the number of disagreements
edges was showed to be NP-hard even on complete graph \autocite{Bansal2002},
although there exists an elegant algorithm by \textcite{Ailon2008} (referred
later as \ccp{}) running in $O(n\left|\mathcal{P}_{\text{\ccp{}}}\right|)$
where $\left|\mathcal{P}_{\text{\ccp{}}}\right| \le |V|$ is the number of
cluster found with this strategy. It is a randomized algorithm with an
expected approximation ratio of $3$.

When the input is a general graph, it becomes APX-hard
\autocites{Charikar2003}{Demaine2006} and these two papers provide polynomial
algorithm achieving $O(\log n)$ approximation. Yet they resort to expensive
semi definite program so we are seeking a combinatorial approach that would
transform a graph into a clique, in order to apply the \ccp{} algorithm.

\section{Method}

We obtain a clique by repeatedly closing triangles according to the following
rules:
\begin{enumerate}[i]
	\item 2 $+$ edges are closed by a $+$ edge;
	\item 1 $+$ and 1 $-$ edges are closed by a $-$ edge;
	\item 2 $-$ edges are not closed, as it does not provide enough
		information.
\end{enumerate}

The full algorithm is presented in \autoref{alg:complete}. The crucial step is
\textsc{PickTriangles} (\autoref{alg:pick}, for as we shall see in the
experiments, it strongly affects the performance in terms of disagreements.

\begin{algorithm}
	\caption{Forming a clique \label{alg:complete}}
	\begin{algorithmic}[0]
		\Let{$C$}{\textsc{FindInitialCloseableTriangles()}}
		\Comment{$C$ is the set of all triangles in the current graph with
			exactly 2 edges satisfying condition i. and ii. in the list above}
		\While{$C \neq{} \emptyset$}
			\ForAll{$triangle$ in \textsc{PickTriangles}$(C)$}
				\State \textsc{Close}$(triangle)$
			\EndFor
			\State \textsc{Update}$(C)$
		\EndWhile
		\State set remaining edges to negative
	\end{algorithmic}
\end{algorithm}



The first decision is whether to start by selecting a distinguished vertex
(called \emph{pivot}) and consider only triangles involving the pivot or
consider all possible triangles. In the second step, we can choose only one
triangle at each iteration or all of the candidates.

\begin{table}[htpb]
	\centering
	\caption{Short names of the different randomization strategy
		\label{tab:strategy}}
	\begin{tabular}{ccc}
		\toprule
		              & pivot & no pivot \\
		\midrule
		one triangle  & $P_1$ & $N_1$ \\
		all triangles & $P_*$ & $N_*$ \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{algorithm}
	\caption{Selecting some triangles to be closed \label{alg:pick}}
	\begin{algorithmic}[0]
		\Function{\textsc{PickTriangles}}{$C$}
			\If{strategy requires a pivot}
				\Let{$pivot$}{sample a vertex between $1$ and $n$ according to
					some distribution
					% over the vertices
					$\mathcal{D}_v$}
				\Let{$candidates$}{all triangles in $C$ to which $pivot$
					belongs}
			\Else
				\Let{$candidates$}{$C$}
			\EndIf
			\If{strategy requires only one triangle}
				\State \textbf{return} a element of $candidates$ sampled
				according to some distribution $\mathcal{D}$
			\Else \Comment{strategy requires all triangles}
				\State \textbf{return} $candidates$
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\section{Experiment}

We try our implementation on different controlled geometry to see how it
behaves. Most of them involve \emph{bad cycle}, that is cycle with exactly one
negative edge that will necessarily incurs at least one disagreement.  Because
our algorithm is randomized, we complete each graph 50 times.  On each
completed graph, we run \ccp{} algorithm 100 times, to obtain an estimation of
the expected cost of the complete graph. In all the following tables, we
report the number of disagreement edges among edges of the original graph.

\subsection{One bad cycle of length $n$}

The optimal solution is either one or two contiguous clusters, yielding one
disagreement. Strategy \pat{} achieves this optimum while \pot{} number of
errors grows linearly with the length $n$ of the cycle.

\begin{center}
\begin{tabular}{lrrrrrrrrr}
\toprule
$n$      & 8   & 16  & 32  & 64   & 128  & 256  & 384   & 512   & 1024 \\
\midrule
\pot{}    & 1.4 & 3.1 & 7.3 & 17.2 & 40.0 & 86.2 & 132.7 & 179.6 & 371.0 \\
\pat{}    & --  & --  & --  & --   & --   & 1.0  & --    & --    & -- \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Cycle of length 100 having only two negative edges separated by
	$k$ vertices}
Because there is more than one negative edge, the optimal solution cost is 0.
It is found consistently by both strategies.

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
$k$ &   0  &   1  &   25 &   50  \\
\midrule
\pot{} & 0.0 & 0.0 & 0.0 & 0.0  \\
\pat{} &  0.0 &  0.0 & 0.0 & 0.0  \\
\bottomrule
\end{tabular}
\end{center}

\subsection{bad squares sharing only one (positive) edge}
Here, the optimal solution is to create two clusters in the following ways.
Say the shared is between vertices $0$ and $1$. Each of them is put in one
cluster. Starting from $0$, we can follow a path on every cycle and put
vertex we cross in $0$'s cluster, until we encounter the negative edge of the
cycle. We do the same with $1$.

\begin{center}
\begin{tabular}{lrrrr}
\toprule
number of squares &  40  &  65  &  80  &  130 \\
\midrule
\pot{} &  2.9 &  2.6 &  2.9 &  2.9 \\
\pat{} & 24.1 & 42.8 & 53.4 & 76.2 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{bad squares sharing only the (negative) edge}

If we move the position of the negative edge to the shared edge, the results
do not change.

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
number of squares &  40  &  65  &  80  &  130 &  170 \\
\midrule
\pot{} &  2.0 &  1.9 &  2.1 &  4.6 &  2.0 \\
\pat{} & 21.8 & 31.7 & 42.6 & 62.6 & 88.2 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{$\floor*{\sqrt{n}}$ bad cycles of length $\floor*{\sqrt{n}}$
	sharing one positive edge}

Since the length of the cycle does not affect the optimal solution, its cost
is still $1$. Since it is the most challenging case, its worth mentioning at
this point than by providing a little help to the algorithm, we can greatly
reduce the number of mistakes. Namely, if we avoid selecting as pivot the
endpoints of the shared edge during the first $n\log n$ iterations, the
number of disagreements drops to $1.2$ for $n=12\times 12$.

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
cycle length &   7  &   9  &   12 &   15 &   20 \\
\midrule
\pot{} & 10.6 & 14.7 & 16.3 & 32.5 & 55.1 \\
\pat{} &  6.8 &  8.8 & 12.0 & 15.1 & 20.1 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Planted clustering}

We create $k$ clusters $\{C_1, \ldots, C_k\}$ of roughly the same size $n_i$
with around $2n$ positive edges inside them and $n_i\cdot n_j$ negative edges
across each others. Then we flip a fraction $p=0.07$ of edges are random,
which us an estimation of the optimal number of disagreement, provided that
the clustering stays the same. A similar model is considered by
\textcite{Makarychev2014}.

In the table below, we report the number of disagreement divided by the
number of flipped edges, that is an estimation of the approximation ratio of
our method.

\begin{center}
\begin{tabular}{lrrrrrrrrr}
\toprule
$k$      & 5   & 10  & 30  & 20  & 15  & 2   & 2   & 2   & 2  \\
$n$      & 15  & 25  & 6   & 12  & 35  & 20  & 40  & 65  & 100 \\
nodes    & 75  & 250 & 180 & 240 & 525 & 40  & 80  & 130 & 200 \\
\midrule
\pat{}   & 2.2 & 2.1 & 1.6 & 1.7 & 1.9 & 2.0 & 2.5 & 2.6 & 3.0 \\
\pot{}   & 3.2 & 2.8 & 1.7 & 2.0 & 2.4 & 4.5 & 5.9 & 6.5 & 7.0 \\
\bottomrule
\end{tabular}
\end{center}

\section{Discussion}

\begin{itemize}
	\item Which strategy is the best?
	\item Unfortunately, although there is a optimal algorithm to detect all
		cycles in an undirected graph \autocite{Cycles13} which we could
		exploit to avoid choosing bad pivots, in practice we cannot afford
		such an expensive preprocessing step. Yet we could find an heuristic
		achieving a similar outcome.
	\item How to incorporate the fact that edges we are adding are more
		indirect --- especially in the latest stages ---, either in our
		algorithm or by modifying \ccp{}?
	\item The current algorithm has $O(n^3)$ time and space complexity and
		thus is not very scalable. Furthermore, because we are looking for a
		complete graph, it is not immediately clear how to take advantage of a
		distributed setting.
\end{itemize}

% Python implementation is maybe not optimal, rewrite in C++?
