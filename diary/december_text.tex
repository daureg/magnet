\section{Problem}

In \pcc{}, we have a set of $n$ objects and a binary relationship between them
denoting similarity $(+)$  or dissimilarity $(-)$. Such data are naturally
associated with a signed graph $G=(V,E)$. The objective is to cluster them
according to this similarity information.

One advantage of this clustering method is that the number of clusters is part
of the solution as opposed of being an input constraint, which is sometime
desirable in unsupervised setting. Furthermore, it can be performed even when
there is no distance defined between points (although such extra information
can be taken into account through edges weight).

Given any node partition, a \emph{disagreements edge} is a positive edge within a
cluster or a negative edge between different clusters. A natural complexity
measure for the edge labeling (the signs associated with edges) is the minimum
number of disagreement edges over \textbf{all} possible node partitions of the node
set.

The problem of finding a partition minimizing the number of disagreements
edges was showed to be NP-hard even on complete graph \autocite{Bansal2002},
although there exists an elegant algorithm by \textcite{Ailon2008} (referred
later as \ccp{}) running in $O(n\left|\mathcal{P}_{\text{\ccp{}}}\right|)$
where $\left|\mathcal{P}_{\text{\ccp{}}}\right| \le |V|$ is the number of
cluster found with this strategy. It is a randomized algorithm with an
expected approximation ratio of $3$.

When the input is a general graph, it becomes APX-hard
\autocites{Charikar2003}{Demaine2006} and these two papers provide polynomial
algorithm achieving $O(\log n)$ approximation. Yet they resort to expensive
semi definite program so we are seeking a combinatorial approach that would
transform a graph into a clique, in order to apply the \ccp{} algorithm.

\section{Method}

A \emph{triangle} is any set of three nodes, regardless of their order. One
triangle is \emph{closeable} if it satisfies the following conditions:
\begin{enumerate}[i]
	\item it has exactly two edges
	\item at least one edge is positive
\end{enumerate}
Such triangles have a special node called \emph{center} which is the endpoint
of the two edges.
\begin{center}
\begin{tikzpicture}[scale=.2]
	% inner sep=3pt,draw=Black,shape=circle
	\node[] (a) at (0,0) {$a$};
	\node[] (b) at (10,0) {$b$};
	\node[] (p) at (5,-10) {$center$};
	\draw[] (a) -- (p) node[midway,above] {$+$};
	\draw[] (b) -- (p) node[midway,above] {$+$};
\end{tikzpicture}
\end{center}

We obtain a clique by iteratively closing these triangles; by adding to them a
third edge whose sign is the product of the signs of the two existing edges.

The crucial decision is how to choose the triangles to close during the
current iteration. For that, we define a strategy as a pair of boolean
(\pvt{}, \oaat{}). If \pvt{} is true, we first select a vertex $p$ uniformly
at random from $V$ and we restrict candidate triangles to have $p$ as center.
Otherwise, we consider all possible closeable triangles as candidates.  Then,
if \oaat{} is true, we select one triangle uniformly at random from the
candidates, otherwise we return all of them. These four strategies are given
names in \autoref{tab:strategy} and the method discussed is formally described
in \autoref{alg:pick}, where $C$ is the set of all currently closeable
triangles in $G$.

\begin{table}[htpb]
	\centering
	\caption{Short names of the different randomization strategy
		\label{tab:strategy}}
	\begin{tabular}{lccc}
		\toprule
		& & \multicolumn{2}{c}{\pvt{}} \\
		    &          & True & False \\
		\midrule
		\multirow{2}{*}{\oaat{}} & True   & $P_1$ & $N_1$ \\
		& False & $P_*$ & $N_*$ \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{algorithm}
	\caption{Selecting some triangles to be closed \label{alg:pick}}
	\begin{algorithmic}[0]
		\Function{\textsc{PickTriangles}}{$G=(V,E),\,strategy,\, pivot,\, C$}
			\If{$strategy.$\pvt{}}
				\Let{$pivot$}{one element from $V$ selected uniformly at
					random}
				\Let{$candidates$}{$\{t \in C : center(t) = pivot\}$}
			\Else
				\Let{$candidates$}{$C$}
			\EndIf
			\If{$strategy.$\oaat{}}
				\State \textbf{return} a element of $candidates$ uniformly at
				random 
			\Else
				\State \textbf{return} $candidates$
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}


The full algorithm is presented in \autoref{alg:complete}.

\begin{algorithm}
	\caption{Forming a clique \label{alg:complete}}
	\begin{algorithmic}[0]
		\Function{\textsc{Complete}}{$G=(V,E),\,strategy$}
			\Let{$C$}{$\emptyset$}
			\ForAll{$triangle$ in $\binom{V}{3}$}
			\If{$triangle$ is closeable}
				\Let{$C$}{$C \cup \{triangle\}$}
			\EndIf
			\EndFor
			\While{$C \neq{} \emptyset$}
				\ForAll{$triangle$ in \textsc{PickTriangles}$(C)$}
					\State \textsc{Close}$(triangle)$
				\EndFor
				\State \textsc{Update}$(C)$
			\EndWhile
			\State set remaining edges to negative
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\section{Experiment}

We try our implementation on different controlled geometry to see how it
behaves. Most of them involve \emph{bad cycle}, that is cycle with exactly one
negative edge that will necessarily incurs at least one disagreement.  Because
our algorithm is randomized, we complete each graph 50 times.  On each
completed graph, we run \ccp{} algorithm 100 times, to obtain an estimation of
the expected cost of the complete graph. In all the following tables, we
report the number of disagreement edges among edges of the original graph.

\subsection{One bad cycle of length $n$}
\label{sub:cycle}

The optimal solution is either one or two contiguous clusters, yielding one
disagreement. Strategy \pat{} achieves this optimum while \pot{} number of
errors grows linearly with the length $n$ of the cycle.

\begin{center}
\begin{tabular}{lrrrrrrrrr}
\toprule
$n$      & 8   & 16  & 32  & 64   & 128  & 256  & 384   & 512   & 1024 \\
\midrule
\pot{}   & 1.4 & 3.1 & 7.3 & 17.2 & 40.0 & 86.2 & 132.7 & 179.6 & 371.0 \\
\pat{}   & --  & --  & --  & --   & --   & 1.0  & --    & --    & -- \\
\nnot{}  & 1.4 & 2.6 & 5.1 & 7.3  & 11.2 & 17.9 &       &       & \\
\nat{}   & 1.0 & 1.0 & 1.0 & 1.0  & 1.0  & 1.0  &       &       & \\
\bottomrule
\end{tabular}
\end{center}



\subsection{Cycle of length 100 having only two negative edges separated by
	$k$ vertices}
Because there is more than one negative edge, the optimal solution cost is 0.
It is found consistently by both strategies.

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
$k$ &   0  &   1  &   25 &   50  \\
\midrule
\pot{} & 0.0 & 0.0 & 0.0 & 0.0  \\
\pat{} &  0.0 &  0.0 & 0.0 & 0.0  \\
\bottomrule
\end{tabular}
\end{center}

\subsection{bad squares sharing only one (positive) edge}
\label{sub:squares}
Here, the optimal solution is to create two clusters in the following ways.
Say the shared is between vertices $0$ and $1$. Each of them is put in one
cluster. Starting from $0$, we can follow a path on every cycle and put
vertex we cross in $0$'s cluster, until we encounter the negative edge of the
cycle. We do the same with $1$.

\begin{center}
\begin{tabular}{lrrrr}
\toprule
number of squares & 40   & 65   & 80    & 130 \\
\midrule
\pot{}            & 2.9  & 2.6  & 2.9   & 2.9 \\
\pat{}            & 24.1 & 42.8 & 53.4  & 76.2 \\
\nnot{}           & 49.9 & 84.8 & 108.6 & 184.2 \\
\nat{}            & 40.0 & 65.0 & 80.0  & 130.0\\
\bottomrule
\end{tabular}
\end{center}


\subsection{bad squares sharing only the (negative) edge}

If we move the position of the negative edge to the shared edge, the results
do not change.

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
number of squares &  40  &  65  &  80  &  130 &  170 \\
\midrule
\pot{} &  2.0 &  1.9 &  2.1 &  4.6 &  2.0 \\
\pat{} & 21.8 & 31.7 & 42.6 & 62.6 & 88.2 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{$\floor*{\sqrt{n}}$ bad cycles of length $\floor*{\sqrt{n}}$
	sharing one positive edge}
\label{sub:mixed}

Since the length of the cycle does not affect the optimal solution, its cost
is still $1$. Since it is the most challenging case, its worth mentioning at
this point than by providing a little help to the algorithm, we can greatly
reduce the number of mistakes. Namely, if we avoid selecting as pivot the
endpoints of the shared edge during the first $n\log n$ iterations, the
number of disagreements drops to $1.2$ for $n=12\times 12$.

\begin{center}
\begin{tabular}{lrrrrr}
\toprule
cycle length & 7    & 9    & 12   & 15   & 20 \\
\midrule
\pot{}       & 10.6 & 14.7 & 16.3 & 32.5 & 55.1 \\
\pat{}       & 6.8  & 8.8  & 12.0 & 15.1 & 20.1 \\
\nnot{}      & 17.2 & 23.9 & 32.2 & 41.6 & 58.7 \\
\nat{}       & 9.1  & 12.1 & 19.8 & 19.3 & 35.3 \\
\bottomrule
\end{tabular}
\end{center}


\subsection{Planted clustering}

We create $k$ clusters $\{C_1, \ldots, C_k\}$ of roughly the same size $n_i$
with around $2n$ positive edges inside them and $n_i\cdot n_j$ negative edges
across each others. Then we flip a fraction $p=0.07$ of edges are random,
which us an estimation of the optimal number of disagreement, provided that
the clustering stays the same. A similar model is considered by
\textcite{Makarychev2014}.

In the table below, we report the number of disagreement divided by the
number of flipped edges, that is an estimation of the approximation ratio of
our method.

\begin{center}
\begin{tabular}{lrrrrrrrrr}
\toprule
$k$      & 5   & 10  & 30  & 20  & 15  & 2   & 2   & 2   & 2  \\
$n$      & 15  & 25  & 6   & 12  & 35  & 20  & 40  & 65  & 100 \\
nodes    & 75  & 250 & 180 & 240 & 525 & 40  & 80  & 130 & 200 \\
\midrule
\pat{}   & 2.2 & 2.1 & 1.6 & 1.7 & 1.9 & 2.0 & 2.5 & 2.6 & 3.0 \\
\pot{}   & 3.2 & 2.8 & 1.7 & 2.0 & 2.4 & 4.5 & 5.9 & 6.5 & 7.0 \\
\bottomrule
\end{tabular}
\end{center}

\section{Discussion}

None of the strategy work well in all case. \pot{} is good for many squares
whereas \pat{} is optimal for one long bad cycle, and both fail in the middle
case of \autoref{sub:mixed}. Yet we mentioned than by avoiding selecting
endpoints of shared edges, results are dramatically improved. One way to get
closer to this behavior is to discard sampling uniformly at random. This can
be done in many ways, here are two of them:

\begin{description}
	\item[Preferential attachment] We maintain for each node $p$ a count
		$p_c$ of how many time $p$ has been selected as pivot so far. Then at
		each iteration, pivot are choosen proportionally to $1+p_c^\alpha$.
		In the beginning, each node is roughly selected as often as the
		others, like in \pot{}. But at some point, a few become preeminent
		and their triangles are closed at a much higher rate, thus
		mimicking \pat{}.
	\item[Degree sequence] This one is a modification of \pat{}. From the
		original graph $G$, we create a vector $D=\{d_1, \ldots, d_k\}$
		containing the unique elements of the sorted degree sequence of $G$. That is,
		$d_1$ is the smallest degree, and $d_2 > d_1$ is the next larger  degree.
	We set $i=1$ initially and in \textsc{PickTriangles}, we choose pivot
	only among nodes with degree less or equal than $d_i$. When there is no more
	possible choice, we increment $i$. In the long bad cycle case, all nodes
	have degree $2$ so this is exactly \pat{}, which is optimal. When many
	cycles share an edge, its endpoints have high degree and are thus
	selected only at the end.
\end{description}

Other unsorted comments:
\begin{itemize}
	\item Another way of experimenting, leaning more toward link classification,
		is to take a subgraph of signed network (like Slashdot or Epinions
		\autocite{Leskovec2010}), hide some edges, cluster nodes with our
		algorithm and predict signs according to whether edge endpoints are in
		the same cluster or not.
	\item Once we choose one strategy, do analysis in complement to
		experiments
	% \item Unfortunately, although there is a optimal algorithm to detect all
	% 	cycles in an undirected graph \autocite{Cycles13} which we could
	% 	exploit to avoid choosing bad pivots, in practice we cannot afford
	% 	such an expensive preprocessing step. Yet we could find an heuristic
	% 	achieving a similar outcome.
	% \item How to incorporate the fact that edges we are adding are more
	% 	indirect --- especially in the latest stages ---, either in our
	% 	algorithm or by modifying \ccp{}?
	\item The current algorithm has $O(n^3)$ time and space complexity and
		thus is not very scalable. Furthermore, because we are looking for a
		complete graph, it is not immediately clear how to take advantage of a
		distributed setting.
\end{itemize}

% Python implementation is maybe not optimal, rewrite in C++?
